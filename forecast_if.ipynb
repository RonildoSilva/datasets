{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RonildoSilva/datasets/blob/main/forecast_if.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump"
      ],
      "metadata": {
        "id": "1SpPNaTtQ7fO"
      },
      "id": "1SpPNaTtQ7fO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Huj2F3JFQ_3F"
      },
      "id": "Huj2F3JFQ_3F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b8558057",
        "outputId": "f6b1e8b8-5524-46ab-e0e6-9d2332243a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flood-forecast\n",
            "  Downloading flood_forecast-0.99998.dev0-py3-none-any.whl (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 35.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (0.11.2)\n",
            "Collecting plotly~=5.7.0\n",
            "  Downloading plotly-5.7.0-py2.py3-none-any.whl (28.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.8 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (1.0.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (1.18.1)\n",
            "Collecting google-cloud\n",
            "  Downloading google_cloud-0.34.0-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting wandb==0.12.17\n",
            "  Downloading wandb-0.12.17-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (1.12.1+cu113)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (1.8.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (2.23.0)\n",
            "Collecting sphinx-autodoc-typehints\n",
            "  Downloading sphinx_autodoc_typehints-1.19.4-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (0.16.0)\n",
            "Collecting shap==0.40.0\n",
            "  Downloading shap-0.40.0-cp37-cp37m-manylinux2010_x86_64.whl (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (3.1.0)\n",
            "Collecting setuptools~=62.0.0\n",
            "  Downloading setuptools-62.0.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 55.4 MB/s \n",
            "\u001b[?25hCollecting mpld3>=0.5\n",
            "  Downloading mpld3-0.5.8-py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 69.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (0.13.1+cu113)\n",
            "Requirement already satisfied: numba>=0.50 in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (0.56.2)\n",
            "Collecting tb-nightly\n",
            "  Downloading tb_nightly-2.11.0a20221003-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2022.1 in /usr/local/lib/python3.7/dist-packages (from flood-forecast) (2022.2.1)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap==0.40.0->flood-forecast) (21.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap==0.40.0->flood-forecast) (4.64.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap==0.40.0->flood-forecast) (1.7.3)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap==0.40.0->flood-forecast) (1.5.0)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.17->flood-forecast) (3.17.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.17->flood-forecast) (6.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.17->flood-forecast) (5.4.8)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.17->flood-forecast) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 41.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.17->flood-forecast) (7.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.17->flood-forecast) (1.15.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 57.6 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.17->flood-forecast) (2.8.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb==0.12.17->flood-forecast) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mpld3>=0.5->flood-forecast) (3.2.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mpld3>=0.5->flood-forecast) (2.11.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->flood-forecast) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->flood-forecast) (4.12.0)\n",
            "Collecting numba>=0.50\n",
            "  Downloading numba-0.56.0-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap==0.40.0->flood-forecast) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly~=5.7.0->flood-forecast) (8.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flood-forecast) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flood-forecast) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flood-forecast) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flood-forecast) (2022.6.15)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.1->flood-forecast) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.1->flood-forecast) (3.1.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 59.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 9.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 31.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 41.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 48.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 59.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 53.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 45.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 18.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.6.0->flood-forecast) (7.1.2)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->flood-forecast) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->flood-forecast) (1.0.3)\n",
            "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->flood-forecast) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage->flood-forecast) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage->flood-forecast) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage->flood-forecast) (4.9)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->flood-forecast) (1.31.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->flood-forecast) (1.56.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage->flood-forecast) (0.4.8)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->flood-forecast) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.50->flood-forecast) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mpld3>=0.5->flood-forecast) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpld3>=0.5->flood-forecast) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpld3>=0.5->flood-forecast) (0.11.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->flood-forecast) (2.6.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->flood-forecast) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->flood-forecast) (1.2.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->flood-forecast) (1.4.1)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx->flood-forecast) (0.17.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->flood-forecast) (2.2.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->flood-forecast) (2.10.3)\n",
            "Collecting sphinx\n",
            "  Downloading sphinx-5.2.3-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 36.6 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 16.2 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx->flood-forecast) (1.1.5)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 72.2 MB/s \n",
            "\u001b[?25hCollecting Pygments>=2.0\n",
            "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 64.3 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 11.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->flood-forecast) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->flood-forecast) (1.48.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->flood-forecast) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->flood-forecast) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->flood-forecast) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->flood-forecast) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->flood-forecast) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->flood-forecast) (0.4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->flood-forecast) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->flood-forecast) (3.2.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=74122686926e455a3a6cf8cb6f6c77b7a3585282ed42f06728b14faf268f5f8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: setuptools, smmap, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, Pygments, jinja2, gitdb, sphinx, slicer, shortuuid, setproctitle, sentry-sdk, pathtools, numba, GitPython, docker-pycreds, wandb, tb-nightly, sphinx-rtd-theme, sphinx-autodoc-typehints, shap, plotly, mpld3, google-cloud, flood-forecast\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 1.8.6\n",
            "    Uninstalling Sphinx-1.8.6:\n",
            "      Successfully uninstalled Sphinx-1.8.6\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.2\n",
            "    Uninstalling numba-0.56.2:\n",
            "      Successfully uninstalled numba-0.56.2\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 Pygments-2.13.0 docker-pycreds-0.4.0 flood-forecast-0.99998.dev0 gitdb-4.0.9 google-cloud-0.34.0 jinja2-3.1.2 mpld3-0.5.8 numba-0.56.0 pathtools-0.1.2 plotly-5.7.0 sentry-sdk-1.9.0 setproctitle-1.3.2 setuptools-62.0.0 shap-0.40.0 shortuuid-1.0.9 slicer-0.0.7 smmap-5.0.0 sphinx-5.2.3 sphinx-autodoc-typehints-1.19.4 sphinx-rtd-theme-1.0.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 tb-nightly-2.11.0a20221003 wandb-0.12.17\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources",
                  "pygments",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "! pip install flood-forecast"
      ],
      "id": "b8558057"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XgIRFDxzHkb"
      },
      "outputs": [],
      "source": [
        "#! git clone https://github.com/AIStream-Peelout/flow-forecast.git"
      ],
      "id": "8XgIRFDxzHkb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkvQQVm-iHt0",
        "outputId": "0267740f-ecab-49bd-d88a-8bfca931d67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=b53de01aa978543747ef7c9733e5196a9d697ffe50b666ac2c53121c38e57c2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "! pip install wget"
      ],
      "id": "zkvQQVm-iHt0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "7Hp_jq8QWSt8",
        "outputId": "62f0814d-3044-460a-c01f-c05aeee3ac2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nos.chdir('flow-forecast')\\n\\n!pip install pandas --upgrade --force\\n!pip install -r  requirements.txt\\n!python setup.py develop\\n!mkdir data\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\"\"\"\n",
        "os.chdir('flow-forecast')\n",
        "\n",
        "!pip install pandas --upgrade --force\n",
        "!pip install -r  requirements.txt\n",
        "!python setup.py develop\n",
        "!mkdir data\n",
        "\"\"\""
      ],
      "id": "7Hp_jq8QWSt8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRAB-0hrWyb4",
        "outputId": "b16493af-e6bb-46ac-df8e-955e8d0751cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install wget"
      ],
      "id": "iRAB-0hrWyb4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0UO6wwpiRlX"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import os.path"
      ],
      "id": "V0UO6wwpiRlX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioHBvdJBiRnn"
      },
      "outputs": [],
      "source": [
        "#! unzip 01010500FVE_flow.csv.zip"
      ],
      "id": "ioHBvdJBiRnn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOlQ2sBFFemA"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import os.path\n",
        "\n",
        "if(not os.path.exists('df_train_keras_tk.csv')):\n",
        "    wget.download('https://raw.githubusercontent.com/RonildoSilva/datasets/main/df_train_keras_tk.csv')\n",
        "\n",
        "if(not os.path.exists('df_val_keras_tk.csv')):\n",
        "    wget.download('https://raw.githubusercontent.com/RonildoSilva/datasets/main/df_val_keras_tk.csv')\n",
        "\n",
        "if(not os.path.exists('df_test_keras_tk.csv')):\n",
        "    wget.download('https://raw.githubusercontent.com/RonildoSilva/datasets/main/df_test_keras_tk.csv')"
      ],
      "id": "kOlQ2sBFFemA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "i-m4kcrL0bDo",
        "outputId": "7bd46f68-71be-4663-c5fa-8e4e106bbf71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom google.colab import files\\nuploaded = files.upload()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\"\"\"\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\"\"\""
      ],
      "id": "i-m4kcrL0bDo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oHO0yMWeUfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7724cf92-bec8-45ea-b5f8-097254ccba2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_test_keras_tk.csv  df_train_keras_tk.csv  df_val_keras_tk.csv  sample_data\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ],
      "id": "-oHO0yMWeUfR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kfWF1esP3Ts"
      },
      "source": [
        "Merge"
      ],
      "id": "7kfWF1esP3Ts"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv1OEhFmFeoE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.concat([\n",
        "    pd.read_csv('df_train_keras_tk.csv'),\n",
        "    pd.read_csv('df_val_keras_tk.csv'),\n",
        "    pd.read_csv('df_test_keras_tk.csv')\n",
        "])"
      ],
      "id": "bv1OEhFmFeoE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-LlEhN0N3G3",
        "outputId": "6df3210b-c7a6-4b10-8374-55b045fa750d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12363, 20) (3825, 20) (4216, 20)\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    pd.read_csv('df_train_keras_tk.csv').shape,\n",
        "    pd.read_csv('df_val_keras_tk.csv').shape,\n",
        "    pd.read_csv('df_test_keras_tk.csv').shape\n",
        ")"
      ],
      "id": "9-LlEhN0N3G3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WSKxgqxuatO",
        "outputId": "941e71d9-3c21-4d0a-da63-0bfc3a017e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2010-01-13 2012-04-07 2012-02-10 2012-09-20 2012-07-30 2014-01-03\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    pd.to_datetime(pd.read_csv('df_train_keras_tk.csv')['datetime']).dt.strftime('%Y-%m-%d').min(),\n",
        "    pd.to_datetime(pd.read_csv('df_train_keras_tk.csv')['datetime']).dt.strftime('%Y-%m-%d').max(),\n",
        "\n",
        "    pd.to_datetime(pd.read_csv('df_val_keras_tk.csv')['datetime']).dt.strftime('%Y-%m-%d').min(),\n",
        "    pd.to_datetime(pd.read_csv('df_val_keras_tk.csv')['datetime']).dt.strftime('%Y-%m-%d').max(),\n",
        "\n",
        "    pd.to_datetime(pd.read_csv('df_test_keras_tk.csv')['datetime']).dt.strftime('%Y-%m-%d').min(),\n",
        "    pd.to_datetime(pd.read_csv('df_test_keras_tk.csv')['datetime']).dt.strftime('%Y-%m-%d').max(),\n",
        ")"
      ],
      "id": "8WSKxgqxuatO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRwOYLo5M-bf"
      },
      "outputs": [],
      "source": [
        "TRAIN_START = 0\n",
        "TRAIN_END = pd.read_csv('df_train_keras_tk.csv').shape[0]\n",
        "#TRAIN_END = 100\n",
        "\n",
        "VAL_START = TRAIN_END + 1\n",
        "VAL_END = VAL_START + pd.read_csv('df_val_keras_tk.csv').shape[0]\n",
        "#VAL_END = VAL_START + 50\n",
        "\n",
        "TEST_START = VAL_END + 1\n",
        "TEST_END = TEST_START + pd.read_csv('df_test_keras_tk.csv').shape[0] - 1\n",
        "#TEST_END = TEST_START + 50"
      ],
      "id": "FRwOYLo5M-bf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF0O28-GQi5I",
        "outputId": "27127407-f039-49b7-e8db-2c07197c39c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 12363 12364 16189 16190 20405\n"
          ]
        }
      ],
      "source": [
        "print(TRAIN_START, TRAIN_END, VAL_START, VAL_END, TEST_START, TEST_END)"
      ],
      "id": "rF0O28-GQi5I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqCX0hzg0Vt5",
        "outputId": "30505f60-21dc-47da-f69a-aa2f393db7b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2012-07-30', '2014-01-03')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "DATETIME_START = pd.to_datetime(pd.read_csv('df_test_keras_tk.csv')['datetime']).dt.strftime('%Y-%m-%d').min()\n",
        "DATETIME_END = pd.to_datetime(pd.read_csv('df_test_keras_tk.csv')['datetime']).dt.strftime('%Y-%m-%d').max()\n",
        "\n",
        "#DATETIME_START = pd.read_csv('df_test_keras_tk.csv')['datetime'][0]\n",
        "#DATETIME_END = pd.to_datetime(pd.read_csv('df_test_keras_tk.csv')['datetime']).dt.strftime('%Y-%m-%d %H:%m:%S+00:00')[TEST_END]\n",
        "\n",
        "DATETIME_START, DATETIME_END"
      ],
      "id": "sqCX0hzg0Vt5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujuPA3And6Mv"
      },
      "source": [
        "2012-07-30 10:55:06"
      ],
      "id": "ujuPA3And6Mv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N6AYKwBM-dc"
      },
      "outputs": [],
      "source": [
        "df['datetime'] = pd.to_datetime(df['datetime']).dt.strftime('%Y-%m-%d')\n",
        "#df['datetime'] = pd.to_datetime(df['datetime']).dt.strftime('%Y-%m-%d %H:%m:%S+00:00')\n",
        "#2000-04-04 04:00:00+00:00"
      ],
      "id": "1N6AYKwBM-dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7iJv5SmM-fm"
      },
      "outputs": [],
      "source": [
        "#df = df[[\"TimeConclusion\", \"Duration\", \"datetime\"]]\n",
        "df.to_csv('df_full.csv', index=False)"
      ],
      "id": "t7iJv5SmM-fm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9n2JosxiCwMk",
        "outputId": "341e30bb-3e8e-4c99-8388-a2bd2836c1fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9  10  11  12  13  14    datetime  Duration  \\\n",
              "0  1  0  0  0  0  0  0  0  0  0   0   0   0   0   0  2010-01-13    0.0000   \n",
              "1  1  2  0  0  0  0  0  0  0  0   0   0   0   0   0  2010-01-29   16.0084   \n",
              "2  1  2  3  0  0  0  0  0  0  0   0   0   0   0   0  2010-01-29    0.0001   \n",
              "3  1  2  3  5  0  0  0  0  0  0   0   0   0   0   0  2010-02-13   15.0002   \n",
              "4  1  0  0  0  0  0  0  0  0  0   0   0   0   0   0  2010-01-13    0.0000   \n",
              "\n",
              "   PassedTime  Step  TimeConclusion  \n",
              "0      0.0000     1         31.0087  \n",
              "1     15.0002     2         15.0003  \n",
              "2     15.0003     3         15.0002  \n",
              "3     31.0087     4          0.0000  \n",
              "4      0.0000     1         30.9822  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a521841f-3ec4-4f9e-b6e8-271228be44bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>datetime</th>\n",
              "      <th>Duration</th>\n",
              "      <th>PassedTime</th>\n",
              "      <th>Step</th>\n",
              "      <th>TimeConclusion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-13</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>31.0087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-29</td>\n",
              "      <td>16.0084</td>\n",
              "      <td>15.0002</td>\n",
              "      <td>2</td>\n",
              "      <td>15.0003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-29</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>15.0003</td>\n",
              "      <td>3</td>\n",
              "      <td>15.0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-02-13</td>\n",
              "      <td>15.0002</td>\n",
              "      <td>31.0087</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-13</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>30.9822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a521841f-3ec4-4f9e-b6e8-271228be44bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a521841f-3ec4-4f9e-b6e8-271228be44bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a521841f-3ec4-4f9e-b6e8-271228be44bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df.head()"
      ],
      "id": "9n2JosxiCwMk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3rPU2ejAFep6",
        "outputId": "6a80c56f-5aaa-4d2a-f332-74e39c9f1d68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install -Uqq ipdb\\nimport ipdb\\n%pdb on\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\"\"\"\n",
        "!pip install -Uqq ipdb\n",
        "import ipdb\n",
        "%pdb on\n",
        "\"\"\""
      ],
      "id": "3rPU2ejAFep6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE23st5CLvxD"
      },
      "outputs": [],
      "source": [
        "FEATURE_COLS = df.columns.tolist()\n",
        "FEATURE_COLS.remove('datetime')\n",
        "#FEATURE_COLS.sort(reverse=True)\n",
        "TARGET_COL = [\"TimeConclusion\"]"
      ],
      "id": "wE23st5CLvxD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_-0f_smXaLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7abe8d35-6df7-4cb7-f082-b0d305414a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', 'Duration', 'PassedTime', 'Step', 'TimeConclusion']\n"
          ]
        }
      ],
      "source": [
        "print(FEATURE_COLS, sep='')"
      ],
      "id": "w_-0f_smXaLW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQnf0D8iXfWh"
      },
      "outputs": [],
      "source": [],
      "id": "hQnf0D8iXfWh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDSAyNme2xCb"
      },
      "outputs": [],
      "source": [
        "#FEATURE_COLS = ['TimeConclusion', 'Duration', 'PassedTime', 'Step', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14']\n",
        "#FEATURE_COLS = ['TimeConclusion', 'Duration', 'PassedTime', 'Step']\n",
        "FEATURE_COLS = ['TimeConclusion', 'PassedTime']"
      ],
      "id": "yDSAyNme2xCb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YfEmhvpz5bA"
      },
      "outputs": [],
      "source": [
        "#FEATURE_COLS = ['Duration', 'PassedTime', 'Step', 'TimeConclusion']"
      ],
      "id": "-YfEmhvpz5bA"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_l2E5V29umob"
      },
      "id": "_l2E5V29umob",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt1foMeWaV6-"
      },
      "outputs": [],
      "source": [
        "DIMENSION_FEAT = len(FEATURE_COLS)"
      ],
      "id": "Wt1foMeWaV6-"
    },
    {
      "cell_type": "code",
      "source": [
        "DIMENSION_FEAT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43heumUn9ylu",
        "outputId": "b9ac36c0-6313-4d70-a3a1-507f74957857"
      },
      "id": "43heumUn9ylu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zX4Ep5MVyNv",
        "outputId": "7242e350-05fa-453d-d3d6-6b3308d82520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['TimeConclusion', 'PassedTime']\n"
          ]
        }
      ],
      "source": [
        "print(FEATURE_COLS, sep=' ')"
      ],
      "id": "1zX4Ep5MVyNv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNYmoR5fWFuA",
        "outputId": "e736b315-ff59-4ff8-a87c-bbd2bc5aacdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['TimeConclusion']\n"
          ]
        }
      ],
      "source": [
        "print(TARGET_COL)"
      ],
      "id": "VNYmoR5fWFuA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPt5W__jQ8mJ"
      },
      "source": [
        "Config"
      ],
      "id": "hPt5W__jQ8mJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-Y6vnprzk1k"
      },
      "outputs": [],
      "source": [
        "PROJECT_NAME = 'if-hd17-flow-forecast'"
      ],
      "id": "l-Y6vnprzk1k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ5EZgX2gi40"
      },
      "source": [
        "https://github.com/AIStream-Peelout/flow-forecast/blob/master/flood_forecast/model_dict_function.py#L23-L35"
      ],
      "id": "DZ5EZgX2gi40"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TkFBYgKgq5b"
      },
      "source": [
        "```\n",
        "pytorch_model_dict = {\n",
        "    \"MultiAttnHeadSimple\": MultiAttnHeadSimple,\n",
        "    \"SimpleTransformer\": SimpleTransformer,\n",
        "    \"TransformerXL\": TransformerXL,\n",
        "    \"DummyTorchModel\": DummyTorchModel,\n",
        "    \"LSTM\": LSTMForecast,\n",
        "    \"SimpleLinearModel\": SimpleLinearModel,\n",
        "    \"CustomTransformerDecoder\": CustomTransformerDecoder,\n",
        "    \"DARNN\": DARNN,\n",
        "    \"DecoderTransformer\": DecoderTransformer,\n",
        "    \"BasicAE\": AE,\n",
        "    \"Informer\": Informer,\n",
        "    \"DSANet\": DSANet\n",
        "}\n",
        "\n",
        "pytorch_criterion_dict = {\n",
        "    \"GaussianLoss\": GaussianLoss,\n",
        "    \"MASELoss\": MASELoss,\n",
        "    \"MSE\": MSELoss,\n",
        "    \"SmoothL1Loss\": SmoothL1Loss,\n",
        "    \"PoissonNLLLoss\": PoissonNLLLoss,\n",
        "    \"RMSE\": RMSELoss,\n",
        "    \"MAPE\": MAPELoss,\n",
        "    \"DilateLoss\": DilateLoss,\n",
        "    \"L1\": L1Loss,\n",
        "    \"PenalizedMSELoss\": PenalizedMSELoss,\n",
        "    \"CrossEntropyLoss\": CrossEntropyLoss,\n",
        "    \"NegativeLogLikelihood\": NegativeLogLikelihood,\n",
        "    \"BCELossLogits\": BCEWithLogitsLoss,\n",
        "    \"FocalLoss\": FocalLoss,\n",
        "    \"BinaryCrossEntropy\": BCELoss\n",
        "}\n",
        "\n",
        "decoding_functions = {\n",
        "  \"greedy_decode\": greedy_decode, \n",
        "  \"simple_decode\": simple_decode\n",
        "}\n",
        "\n",
        "pytorch_opt_dict = {\n",
        "  \"Adam\": Adam,\n",
        "  \"SGD\": SGD,\n",
        "  \"BertAdam\": BertAdam\n",
        "}\n",
        "```"
      ],
      "id": "0TkFBYgKgq5b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgqneH_N14Su",
        "outputId": "04316859-51b0-4380-e5e8-84026f768178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ],
      "id": "qgqneH_N14Su"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6Ckdoi0Q7yT"
      },
      "outputs": [],
      "source": [
        "def make_config_file(flow_file_path, weight_path=None):\n",
        "  run = wandb.init(project=PROJECT_NAME)\n",
        "  wandb_config = run.config\n",
        "  the_wandb_c = run.config\n",
        "  the_config4 =  {                  \n",
        "    \"model_name\": \"Informer\",\n",
        "    \"use_decoder\": True,\n",
        "    \"model_type\": \"PyTorch\",\n",
        "    \"model_params\": {\n",
        "      \"n_time_series\": DIMENSION_FEAT,\n",
        "      \"dec_in\": DIMENSION_FEAT,\n",
        "      \"c_out\": 1,\n",
        "      \"seq_len\":18,#20\n",
        "      \"label_len\":1,#10 \n",
        "      \"out_len\":2,\n",
        "      \"factor\":2,\n",
        "      \"dropout\": 0.001\n",
        "   },\n",
        "    \"dataset_params\":\n",
        "    { \"class\": \"TemporalLoader\",\n",
        "      \"temporal_feats\": [\"month\", \"day\", \"day_of_week\", \"hour\"],\n",
        "       \"training_path\": flow_file_path,\n",
        "       \"validation_path\": flow_file_path,\n",
        "       \"test_path\": flow_file_path,\n",
        "       \"batch_size\":1000,\n",
        "       \"forecast_history\":18,\n",
        "       \"forecast_length\":1,\n",
        "       \"train_end\": TRAIN_END,\n",
        "       \"valid_start\":VAL_START,\n",
        "       \"valid_end\": VAL_END,\n",
        "       \"test_start\": TEST_START,\n",
        "       \"test_end\": TEST_END,\n",
        "       \"target_col\": TARGET_COL,\n",
        "       \"relevant_cols\": FEATURE_COLS,\n",
        "       \"scaler\": \"RobustScaler\", \n",
        "       \"sort_column\":\"datetime\",\n",
        "       \"interpolate\": False,\n",
        "       \"feature_param\":\n",
        "     {\n",
        "         \"datetime_params\":{\n",
        "            \"month\": \"numerical\",\n",
        "            \"day\": \"numerical\",\n",
        "            \"day_of_week\": \"numerical\",\n",
        "            \"hour\":\"numerical\"\n",
        "         }\n",
        "     }\n",
        "    },\n",
        "    \"early_stopping\":\n",
        "    {\n",
        "       \"patience\": 20\n",
        "\n",
        "    },\n",
        "    \"training_params\":\n",
        "    {\n",
        "       \"criterion\":\"L1\",\n",
        "       \"optimizer\": \"BertAdam\",#\"Adam\",#\"SGD\",\n",
        "       \"optim_params\":\n",
        "       {\n",
        "        \"lr\": 0.0001,\n",
        "       },\n",
        "       \"epochs\": 1000,\n",
        "       \"batch_size\":1000\n",
        "    },\n",
        "    \"GCS\": False,\n",
        "    \"wandb\":False,\n",
        "    \"sweep\": True,\n",
        "    #\"wandb\": {\n",
        "    #   \"name\": \"flood_forecast_circleci\",\n",
        "    #   \"tags\": [\"dummy_run\", \"circleci\"],\n",
        "    #   \"project\":\"repo-flood_forecast\"\n",
        "    #},\n",
        "    \"forward_params\":{\n",
        "    },\n",
        "   \"metrics\":[\"MSE\",\"L1\"],\n",
        "   \"inference_params\":\n",
        "   {     \n",
        "         \"datetime_start\": DATETIME_START,\n",
        "          \"hours_to_forecast\":600, \n",
        "          \"test_csv_path\": flow_file_path,\n",
        "          \"decoder_params\":{\n",
        "            \"decoder_function\": \"simple_decode\",#\"greedy_decode\", \n",
        "            \"unsqueeze_dim\": 1},\n",
        "          \"dataset_params\":{\n",
        "             \"file_path\": flow_file_path,\n",
        "             \"forecast_history\":18,\n",
        "             \"forecast_length\":3,\n",
        "             \"relevant_cols\": FEATURE_COLS,\n",
        "             \"target_col\": TARGET_COL,\n",
        "             \"scaling\": \"RobustScaler\",\n",
        "             \"interpolate_param\": False,\n",
        "             \"sort_column\":\"datetime\",\n",
        "             \"feature_params\":\n",
        "             {\n",
        "                 \"datetime_params\":{\n",
        "                    \"month\": \"numerical\",\n",
        "                    \"day\": \"numerical\",\n",
        "                    \"day_of_week\": \"numerical\",\n",
        "                    \"hour\":\"numerical\"\n",
        "                 }\n",
        "             }\n",
        "          }\n",
        "   }\n",
        "   }\n",
        "\n",
        "      \n",
        "  if weight_path:\n",
        "    the_config4[\"weight_path\"] = weight_path\n",
        "  wandb.config.update(the_config4)\n",
        "  print(\"config made\")\n",
        "  return the_config4\n",
        "  \n",
        "wandb_sweep_config_full = {\n",
        "\"name\": \"Default sweep\",\n",
        "  \"method\": \"grid\",\n",
        "  \"parameters\": {\n",
        "        \"forecast_length\":{\n",
        "            \"values\":[3]#[1, 2, 3]\n",
        "            }\n",
        "            ,\n",
        "        \"batch_size\": {\n",
        "            \"values\": [500]\n",
        "        },\n",
        "        \"lr\":{\n",
        "            \"values\":[0.0001]#[0.01, 0.001, 0.0001]\n",
        "        },\n",
        "        \"forecast_history\":{\n",
        "            \"values\":[18]#[15,30]\n",
        "        },\n",
        "        \"out_seq_length\":{\n",
        "            \"values\":[1]\n",
        "        },\n",
        "        \"hidden_encoder\":\n",
        "        {\n",
        "            \"values\":[18]\n",
        "        },\n",
        "        \"hidden_decoder\":\n",
        "        {\n",
        "            \"values\":[18]\n",
        "        }, \n",
        "        \"dropout\":\n",
        "        {\n",
        "            \"values\": [0.001]#[0.5, 0.2, 0.1,0.01]\n",
        "        }\n",
        "  \n",
        "    }\n",
        "}"
      ],
      "id": "u6Ckdoi0Q7yT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f7e61de24ede4a4fb5d74764b37b53d3",
            "72df380e9fd14a4ab03fcd30b5b21e2d",
            "3ec2a28e8a564115b5ad061c62486b94",
            "91cb40f844d842b2bcdf12c133196b4a",
            "3c67385c2c1745fbb2b249f2761a0420",
            "99cb58c5416745238be88376b0d471d9",
            "d03d00716ba14442933f05d9ce654da1",
            "2760f9dad4ec400eb06f1de53b705428"
          ]
        },
        "id": "648be723",
        "outputId": "b5e1371c-0e5a-4706-9321-41d77bbdd83d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: plqnetb1\n",
            "Sweep URL: https://wandb.ai/ronildosilva/if-hd17-flow-forecast/sweeps/plqnetb1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6hd5aajp with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_decoder: 18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_encoder: 18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tout_seq_length: 1\n",
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mronildosilva\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221003_183008-6hd5aajp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ronildosilva/if-hd17-flow-forecast/runs/6hd5aajp\" target=\"_blank\">balmy-sweep-1</a></strong> to <a href=\"https://wandb.ai/ronildosilva/if-hd17-flow-forecast\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ronildosilva/if-hd17-flow-forecast/sweeps/plqnetb1\" target=\"_blank\">https://wandb.ai/ronildosilva/if-hd17-flow-forecast/sweeps/plqnetb1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['month', 'day', 'day_of_week', 'hour']\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['month', 'day', 'day_of_week', 'hour']\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['month', 'day', 'day_of_week', 'hour']\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 500, 'dropout': 0.001, 'forecast_history': 18, 'forecast_length': 3, 'hidden_decoder': 18, 'hidden_encoder': 18, 'lr': 0.0001, 'out_seq_length': 1, 'model_name': 'Informer', 'use_decoder': True, 'model_type': 'PyTorch', 'model_params': {'n_time_series': 2, 'dec_in': 2, 'c_out': 1, 'seq_len': 18, 'label_len': 1, 'out_len': 2, 'factor': 2, 'dropout': 0.001}, 'dataset_params': {'class': 'TemporalLoader', 'temporal_feats': ['month', 'day', 'day_of_week', 'hour'], 'training_path': 'df_full.csv', 'validation_path': 'df_full.csv', 'test_path': 'df_full.csv', 'batch_size': 1000, 'forecast_history': 18, 'forecast_length': 1, 'train_end': 12363, 'valid_start': 12364, 'valid_end': 16189, 'test_start': 16190, 'test_end': 20405, 'target_col': ['TimeConclusion'], 'relevant_cols': ['TimeConclusion', 'PassedTime'], 'scaler': 'RobustScaler', 'sort_column': 'datetime', 'interpolate': False, 'feature_param': {'datetime_params': {'month': 'numerical', 'day': 'numerical', 'day_of_week': 'numerical', 'hour': 'numerical'}}}, 'early_stopping': {'patience': 20}, 'training_params': {'criterion': 'L1', 'optimizer': 'BertAdam', 'optim_params': {'lr': 0.0001}, 'epochs': 1000, 'batch_size': 1000}, 'GCS': False, 'wandb': False, 'sweep': True, 'forward_params': {}, 'metrics': ['MSE', 'L1'], 'inference_params': {'datetime_start': '2012-07-30', 'hours_to_forecast': 600, 'test_csv_path': 'df_full.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'file_path': 'df_full.csv', 'forecast_history': 18, 'forecast_length': 3, 'relevant_cols': ['TimeConclusion', 'PassedTime'], 'target_col': ['TimeConclusion'], 'scaling': 'RobustScaler', 'interpolate_param': False, 'sort_column': 'datetime', 'feature_params': {'datetime_params': {'month': 'numerical', 'day': 'numerical', 'day_of_week': 'numerical', 'hour': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "running torch_single_train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 580\n",
            "0.0034321142682948937\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04597798176109791\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 581\n",
            "0.003536767827776762\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04780723457224667\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 582\n",
            "0.003677479582480513\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04721374262589961\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 583\n",
            "0.003631826355838432\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.044048412004485726\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 584\n",
            "0.0033883393849604405\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04513167100958526\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 585\n",
            "0.0034716670007373276\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04748932644724846\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 586\n",
            "0.0036530251113268044\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04650775552727282\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 587\n",
            "0.0035775196559440633\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.044179918128065765\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 588\n",
            "0.0033984552406204436\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04538902931381017\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 589\n",
            "0.003491463793370013\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.046641627326607704\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 590\n",
            "0.0035878174866621313\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04618948115967214\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 591\n",
            "0.0035530370122824726\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04286564188078046\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 592\n",
            "0.003297357067752343\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04453773982822895\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 593\n",
            "0.0034259799867868423\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.047043837257660925\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 594\n",
            "0.0036187567121277633\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.046232174267061055\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 595\n",
            "0.003556321097466235\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04348220000974834\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 596\n",
            "0.0033447846161344876\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04471806366927922\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 597\n",
            "0.003439851051483017\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0458200890570879\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 598\n",
            "0.0035246222351606074\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04583112825639546\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 599\n",
            "0.003525471404338112\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04286434571258724\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 600\n",
            "0.0032972573625067105\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04466107813641429\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 601\n",
            "0.0034354675489549455\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.045896334340795875\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 602\n",
            "0.003530487256984298\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.045397607143968344\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 603\n",
            "0.0034921236264591035\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04283865832258016\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 604\n",
            "0.003295281409429243\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04409236868377775\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 605\n",
            "0.0033917206679829038\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04542098834645003\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 606\n",
            "0.003493922180496156\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04527338978368789\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 607\n",
            "0.0034825684448990682\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04287850914988667\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 608\n",
            "0.0032983468576835897\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04352796566672623\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 609\n",
            "0.003348305051286633\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04545593878719956\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 610\n",
            "0.0034966106759384274\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.044918355997651815\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 611\n",
            "0.0034552581536655244\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04291174630634487\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 612\n",
            "0.003300903562026528\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.042989643989130855\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 613\n",
            "0.003306895691471604\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04490049823652953\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 614\n",
            "0.0034538844797330406\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04521018988452852\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 615\n",
            "0.0034777069141945015\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04198917525354773\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 616\n",
            "0.0032299365579652097\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04291503503918648\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 617\n",
            "0.0033011565414758828\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04524329549167305\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 618\n",
            "0.0034802534993594657\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.044432094087824225\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 619\n",
            "0.003417853391371094\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.042331408243626356\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 620\n",
            "0.0032562621725866427\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04268537776079029\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 621\n",
            "0.003283490596983868\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04442633595317602\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 622\n",
            "0.003417410457936617\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04433308029547334\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 623\n",
            "0.0034102369458056414\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04192023759242147\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 624\n",
            "0.003224633660955498\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04270673939026892\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 625\n",
            "0.0032851337992514554\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04453631001524627\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 626\n",
            "0.0034258700011727903\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.043944576173089445\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 627\n",
            "0.0033803520133145726\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04150975123047829\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 628\n",
            "0.0031930577869598684\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.042466134880669415\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 629\n",
            "0.0032666257600514935\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04389308579266071\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 630\n",
            "0.003376391214820055\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0437103376025334\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 631\n",
            "0.0033623336617333386\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0407458069967106\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 632\n",
            "0.0031342928459008154\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04199888103175908\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 633\n",
            "0.0032306831562891603\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0442605041898787\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 634\n",
            "0.003404654168452208\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04319643706548959\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 635\n",
            "0.0033228028511915067\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04062141268514097\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 636\n",
            "0.0031247240527031515\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.042079062201082706\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 637\n",
            "0.0032368509385448238\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.043053306406363845\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 638\n",
            "0.0033117928004895267\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.043788792681880295\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 639\n",
            "0.003368368667836946\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04075743746943772\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 640\n",
            "0.0031351874976490554\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04123893356882036\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 641\n",
            "0.0031722256591400276\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04435167147312313\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 642\n",
            "0.003411667036394087\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04260518867522478\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 643\n",
            "0.0032773222057865216\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04069259774405509\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 644\n",
            "0.003130199826465776\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.041044115205295384\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 645\n",
            "0.003157239631176568\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04280983132775873\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 646\n",
            "0.003293063948289133\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.042449796572327614\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 647\n",
            "0.0032653689671021243\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040552728809416294\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 648\n",
            "0.003119440677647407\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04169450106564909\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 649\n",
            "0.003207269312742238\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.043467237264849246\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 650\n",
            "0.0033436336357576344\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0419858138775453\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 651\n",
            "0.0032296779905804074\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040781245566904545\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 652\n",
            "0.003137018889761888\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.041071478044614196\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 653\n",
            "0.003159344464970323\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04338207351975143\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 654\n",
            "0.0033370825784424176\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.041293949354439974\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 655\n",
            "0.0031764576426492287\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04022341326344758\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 656\n",
            "0.003094108712572891\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04082473844755441\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 657\n",
            "0.003140364495965724\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04297745740041137\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 658\n",
            "0.0033059582615701053\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04252153658308089\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 659\n",
            "0.0032708874294677605\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04006743140053004\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 660\n",
            "0.00308211010773308\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04081726667936891\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 661\n",
            "0.0031397897445668396\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04212714405730367\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 662\n",
            "0.003240549542869513\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0418834185693413\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 663\n",
            "0.0032218014284108695\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.039403381291776896\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 664\n",
            "0.0030310293301366842\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04084189480636269\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 665\n",
            "0.003141684215874053\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.042226749123074114\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 666\n",
            "0.003248211471005701\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04157615150325\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 667\n",
            "0.00319816550025\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03952686279080808\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 668\n",
            "0.0030405279069852372\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040161062381230295\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 669\n",
            "0.003089312490863869\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04195061547216028\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 670\n",
            "0.0032269704209354063\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04162785259541124\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 671\n",
            "0.003202142507339326\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.039510673261247575\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 672\n",
            "0.0030392825585575057\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040077456389553845\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 673\n",
            "0.003082881260734911\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0418434088351205\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 674\n",
            "0.003218723756547731\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.041212328360415995\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 675\n",
            "0.003170179104647384\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03900412342045456\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 676\n",
            "0.0030003171861888124\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03995555581059307\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 677\n",
            "0.003073504293122544\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04140318953432143\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 678\n",
            "0.0031848607334093405\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040869626798667014\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 679\n",
            "0.003143817446051309\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03874871984589845\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 680\n",
            "0.002980670757376804\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03982560324948281\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 681\n",
            "0.0030635079422679087\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.041455297148786485\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 682\n",
            "0.0031888690114451144\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040866082767024636\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 683\n",
            "0.003143544828232664\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03872229077387601\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 684\n",
            "0.002978637751836616\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03959627542644739\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 685\n",
            "0.0030458673404959533\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0413920134305954\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 686\n",
            "0.003184001033122723\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040694005438126624\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 687\n",
            "0.003130308110625125\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0381067463895306\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 688\n",
            "0.002931288183810046\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03963237861171365\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 689\n",
            "0.0030486445085933576\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0410976946586743\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 690\n",
            "0.0031613611275903308\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040621587191708386\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 691\n",
            "0.0031247374762852606\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03809634840581566\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 692\n",
            "0.002930488338908897\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03933494631201029\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 693\n",
            "0.0030257651009238684\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04049722175113857\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 694\n",
            "0.003115170903933736\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04034928139299154\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 695\n",
            "0.003103790876383965\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0383142736973241\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 696\n",
            "0.0029472518228710843\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.038762353477068245\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 697\n",
            "0.0029817194982360187\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040352524956688285\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 698\n",
            "0.0031040403812837144\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04015423043165356\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 699\n",
            "0.003088786956281043\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03752795571926981\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 700\n",
            "0.0028867658245592164\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.038938365411013365\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 701\n",
            "0.002995258877770259\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04014373023528606\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 702\n",
            "0.003087979248868158\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04010079300496727\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 703\n",
            "0.0030846763849974824\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0372840731870383\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 704\n",
            "0.002868005629772177\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03867480717599392\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 705\n",
            "0.0029749851673841476\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.040467639337293804\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 706\n",
            "0.003112895333637985\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.039742555818520486\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 707\n",
            "0.0030571196783477296\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03753124491777271\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 708\n",
            "0.00288701883982867\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03836729913018644\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 709\n",
            "0.0029513307023220337\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04009635769762099\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 710\n",
            "0.0030843352075093067\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03957737656310201\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 711\n",
            "0.0030444135817770776\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03721642144955695\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 712\n",
            "0.002862801649965919\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03837217052932829\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 713\n",
            "0.0029517054253329453\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.04025122232269496\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 714\n",
            "0.003096247870976535\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03920973325148225\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 715\n",
            "0.003016133327037096\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0371487942757085\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 716\n",
            "0.0028575995596698844\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.038214907981455326\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 717\n",
            "0.002939608306265794\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.039732854813337326\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 718\n",
            "0.0030563734471797943\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.039336050976999104\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 719\n",
            "0.0030258500751537774\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03727205656468868\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 720\n",
            "0.002867081274206822\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03790660202503204\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 721\n",
            "0.0029158924634640035\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03974337049294263\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 722\n",
            "0.0030571823456109716\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0389483158942312\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 723\n",
            "0.002996024299556246\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.036625060834921896\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 724\n",
            "0.002817312371917069\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.038179197581484914\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 725\n",
            "0.0029368613524219165\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03937510459218174\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 726\n",
            "0.0030288541993985954\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03913843014743179\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 727\n",
            "0.0030106484728793684\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.036408257437869906\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 728\n",
            "0.0028006351875284542\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0381050513824448\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 729\n",
            "0.0029311577986496\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03926007240079343\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 730\n",
            "0.0030200055692918026\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0386816804530099\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 731\n",
            "0.002975513881000762\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03635890735313296\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 732\n",
            "0.002796839027164074\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.037662566639482975\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 733\n",
            "0.0028971205107294596\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03910195373464376\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 734\n",
            "0.0030078425949725965\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.038569315685890615\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 735\n",
            "0.002966870437376201\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03679513477254659\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 736\n",
            "0.0028303949825035837\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.036996965296566486\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 737\n",
            "0.002845920407428191\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03880053211469203\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 738\n",
            "0.002984656316514772\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03809611685574055\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 739\n",
            "0.0029304705273646573\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03600211103912443\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 740\n",
            "0.0027693931568557252\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.037634355830959976\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 741\n",
            "0.0028949504485353827\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03870376816485077\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 742\n",
            "0.0029772129357577516\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03842954174615443\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 743\n",
            "0.002956118595858033\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.036578114493750036\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 744\n",
            "0.002813701114903849\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.036906094988808036\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 745\n",
            "0.0028389303837544643\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.038536426378414035\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 746\n",
            "0.0029643404906472335\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.038010340416803956\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 747\n",
            "0.0029238723397541503\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03540722816251218\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 748\n",
            "0.00272363293557786\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.037147313356399536\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 749\n",
            "0.002857485642799964\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03832129598595202\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 750\n",
            "0.002947791998919386\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03810412751045078\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 751\n",
            "0.002931086731573137\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03575102554168552\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 752\n",
            "0.002750078887821963\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03650647844187915\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 753\n",
            "0.0028081906493753195\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.037946649361401796\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 754\n",
            "0.002918973027800138\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.037570125074125826\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 755\n",
            "0.002890009621086602\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03548977430909872\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 756\n",
            "0.00272998263916144\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.037111543701030314\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 757\n",
            "0.0028547341308484855\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.038050072733312845\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 758\n",
            "0.002926928671793296\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0378459426574409\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 759\n",
            "0.0029112263582646847\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03514116303995252\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 760\n",
            "0.002703166387688655\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.036348019959405065\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 761\n",
            "0.002796001535338851\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03796264121774584\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 762\n",
            "0.002920203170595834\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03761374484747648\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 763\n",
            "0.0028933649882674217\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.035405342816375196\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 764\n",
            "0.002723487908951938\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.036321627674624324\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 765\n",
            "0.0027939713595864866\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.037608153419569135\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 766\n",
            "0.002892934878428395\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03689859330188483\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 767\n",
            "0.0028383533309142175\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.034910731483250856\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 768\n",
            "0.002685440883326989\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03567948448471725\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 769\n",
            "0.0027445757295936346\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03810213948599994\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 770\n",
            "0.00293093380661538\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03727884613908827\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 771\n",
            "0.0028676035491606365\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03477805352304131\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 772\n",
            "0.002675234886387793\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03588795196264982\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 773\n",
            "0.002760611689434602\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03748694609384984\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 774\n",
            "0.002883611237988449\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.037004150217399\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 775\n",
            "0.002846473093646077\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03458531678188592\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 776\n",
            "0.002660408983221994\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03582211653701961\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 777\n",
            "0.002755547425924585\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03749157162383199\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 778\n",
            "0.002883967047987076\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03683579317294061\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 779\n",
            "0.0028335225517646624\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03396020783111453\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 780\n",
            "0.0026123236793165025\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03601472044829279\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 781\n",
            "0.002770363111407138\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03727008309215307\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 782\n",
            "0.0028669294686271595\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03665388294029981\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 783\n",
            "0.0028195294569461392\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03442415187601\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 784\n",
            "0.00264801168277\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03512389841489494\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 785\n",
            "0.002701838339607303\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03713229123968631\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 786\n",
            "0.0028563300953604854\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.036390132270753384\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 787\n",
            "0.0027992409439041065\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03414077789057046\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 788\n",
            "0.0026262136838900354\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03555508458521217\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 789\n",
            "0.0027350065065547824\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03646301734261215\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 790\n",
            "0.002804847487893242\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03642426384612918\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 791\n",
            "0.0028018664497022447\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03412585286423564\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 792\n",
            "0.0026250656049412032\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03516041347756982\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 793\n",
            "0.0027046471905822936\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03666792099829763\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 794\n",
            "0.002820609307561356\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.036065017338842154\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 795\n",
            "0.002774232102987858\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03401066467631608\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 796\n",
            "0.002616204975101237\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03521941415965557\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 797\n",
            "0.00270918570458889\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03675452515017241\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 798\n",
            "0.002827271165397878\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.035806237487122416\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 799\n",
            "0.0027543259605478784\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03406346868723631\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 800\n",
            "0.0026202668220951008\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03482872107997537\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 801\n",
            "0.002679132390767336\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03655536472797394\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 802\n",
            "0.002811951132921072\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03588977979961783\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 803\n",
            "0.0027607522922782944\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03396189596969634\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 804\n",
            "0.002612453536130488\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03470802016090602\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 805\n",
            "0.002669847704685078\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03607879229821265\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 806\n",
            "0.0027752917152471268\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03591004270128906\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 807\n",
            "0.0027623109770222353\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03381344140507281\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 808\n",
            "0.00260103395423637\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03438805462792516\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 809\n",
            "0.002645234971378858\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03632399043999612\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 810\n",
            "0.0027941531107689324\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.035554504953324795\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 811\n",
            "0.0027349619194865227\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03351906535681337\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 812\n",
            "0.0025783896428317977\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03460500622168183\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 813\n",
            "0.0026619235555139873\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03589338925667107\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 814\n",
            "0.0027610299428208517\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.035789563320577145\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 815\n",
            "0.002753043332352088\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03350984607823193\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 816\n",
            "0.0025776804675563024\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03399857715703547\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 817\n",
            "0.0026152751659258055\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.035975194186903536\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 818\n",
            "0.0027673226297618104\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03533009090460837\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 819\n",
            "0.00271769930035449\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.033050848403945565\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 820\n",
            "0.002542372954149659\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03431134228594601\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 821\n",
            "0.002639334021995847\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03571999853011221\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 822\n",
            "0.002747692194624016\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0350669949548319\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 823\n",
            "0.0026974611503716847\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03330675372853875\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 824\n",
            "0.0025620579791183653\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.033936759806238115\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 825\n",
            "0.0026105199850952397\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03527222550474107\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 826\n",
            "0.0027132481157493135\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.035226031905040145\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 827\n",
            "0.002709694761926165\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03304035170003772\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 828\n",
            "0.002541565515387517\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03438870224636048\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 829\n",
            "0.0026452847881815755\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03520826832391322\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 830\n",
            "0.002708328332608709\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03471326653379947\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 831\n",
            "0.0026702512718307283\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03297989955171943\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 832\n",
            "0.0025369153501322637\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03371230303309858\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 833\n",
            "0.0025932540794691215\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03539006086066365\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 834\n",
            "0.002722312373897204\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03471201623324305\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 835\n",
            "0.00267015509486485\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03253527276683599\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 836\n",
            "0.0025027132897566143\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.033848527702502906\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 837\n",
            "0.0026037329001925313\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.035125514725223184\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 838\n",
            "0.002701962671171014\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.034624733962118626\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 839\n",
            "0.002663441074009125\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03281150257680565\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 840\n",
            "0.002523961736677358\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03350316418800503\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 841\n",
            "0.0025771664760003868\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.035036773537285626\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 842\n",
            "0.002695136425945048\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03452734602615237\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 843\n",
            "0.002655949694319413\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03247158322483301\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 844\n",
            "0.002497814094217924\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03331508417613804\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 845\n",
            "0.0025626987827798496\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03480345639400184\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 846\n",
            "0.002677188953384757\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03443250502459705\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 847\n",
            "0.0026486542326613115\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03217761858832091\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 848\n",
            "0.0024752014298708392\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0332981226965785\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 849\n",
            "0.0025613940535829617\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03494829684495926\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 850\n",
            "0.0026883305265353276\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03440308524295688\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 851\n",
            "0.0026463911725351443\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03227572015020996\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 852\n",
            "0.002482747703862305\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03290365659631789\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 853\n",
            "0.0025310505074090683\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.034270539646968246\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 854\n",
            "0.0026361953574590958\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03404871595557779\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 855\n",
            "0.002619131996582907\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03213430708274245\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 856\n",
            "0.0024718697755955732\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03316127008292824\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 857\n",
            "0.0025508669294560184\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03437242470681667\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 858\n",
            "0.0026440326697551287\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03375671955291182\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 859\n",
            "0.0025966707348393705\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03193869930692017\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 860\n",
            "0.002456823023609244\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03320682398043573\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 861\n",
            "0.002554371075418133\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03406853228807449\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 862\n",
            "0.002620656329851884\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03392937988974154\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 863\n",
            "0.002609952299210888\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03162202693056315\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 864\n",
            "0.0024324636100433194\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03267009719274938\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 865\n",
            "0.00251308439944226\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03440697037149221\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 866\n",
            "0.0026466900285763238\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03346630628220737\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 867\n",
            "0.00257433125247749\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03157163260038942\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 868\n",
            "0.0024285871231068787\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03292242018505931\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 869\n",
            "0.0025324938603891777\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03367877448908985\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 870\n",
            "0.002590674960699219\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03362575068604201\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 871\n",
            "0.0025865962066186163\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03184575727209449\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 872\n",
            "0.0024496736363149607\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03219947556499392\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 873\n",
            "0.002476882735768763\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03369507903698832\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 874\n",
            "0.002591929156691409\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03340572549495846\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 875\n",
            "0.0025696711919198814\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03173756075557321\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 876\n",
            "0.0024413508273517857\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.032068920554593205\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 877\n",
            "0.002466840042661016\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0334428574424237\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 878\n",
            "0.002572527495571054\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03345765091944486\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 879\n",
            "0.0025736654553419123\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031312687206082046\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 880\n",
            "0.002408668246621696\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03206439665518701\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 881\n",
            "0.0024664920503990008\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03353015100583434\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 882\n",
            "0.00257924238506418\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.033183439751155674\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 883\n",
            "0.0025525722885504365\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031459299847483635\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 884\n",
            "0.0024199461421141257\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.032048704102635384\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 885\n",
            "0.0024652849309719526\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03318738692905754\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 886\n",
            "0.0025528759176198105\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03277202136814594\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 887\n",
            "0.002520924720626611\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031682407949119806\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 888\n",
            "0.0024371083037784467\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031593732070177794\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 889\n",
            "0.0024302870823213686\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03313955815974623\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 890\n",
            "0.002549196781518941\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.032994605833664536\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 891\n",
            "0.0025380466025895798\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030912771821022034\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 892\n",
            "0.0023779055246940027\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0320002957014367\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 893\n",
            "0.002461561207802823\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03314987104386091\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 894\n",
            "0.0025499900802969933\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.032938069314695895\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 895\n",
            "0.002533697639591992\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030528873205184937\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 896\n",
            "0.0023483748619373026\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031848760205321014\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 897\n",
            "0.0024499046311785397\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03317869349848479\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 898\n",
            "0.002552207192191138\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03295112680643797\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 899\n",
            "0.00253470206203369\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030267733498476446\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 900\n",
            "0.002328287192190496\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03144643397536129\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 901\n",
            "0.002418956459643176\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03290849050972611\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 902\n",
            "0.002531422346902008\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03254268562886864\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 903\n",
            "0.0025032835099129723\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030958866933360696\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 904\n",
            "0.0023814513025662075\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031161297229118645\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 905\n",
            "0.0023970228637783574\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.032949745771475136\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 906\n",
            "0.0025345958285750104\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03252877446357161\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 907\n",
            "0.002502213420274739\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03050463821273297\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 908\n",
            "0.0023465106317486903\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03164915810339153\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 909\n",
            "0.00243455062333781\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.032546599861234426\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 910\n",
            "0.0025035846047103405\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03207948291674256\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 911\n",
            "0.0024676525320571204\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030433935346081853\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 912\n",
            "0.002341071949698604\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031323222210630774\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 913\n",
            "0.002409478631586983\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03252186893951148\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 914\n",
            "0.0025016822261162675\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03202586865518242\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 915\n",
            "0.0024635283580909553\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03023549751378596\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 916\n",
            "0.0023258075010604584\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031275350134819746\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 917\n",
            "0.0024057961642169035\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.032200517249293625\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 918\n",
            "0.002476962865330279\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03197138023097068\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 919\n",
            "0.0024593369408438983\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03015449200756848\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 920\n",
            "0.0023195763082744982\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03083940246142447\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 921\n",
            "0.002372261727801882\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0324105613399297\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 922\n",
            "0.0024931201030715154\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03177296067588031\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 923\n",
            "0.0024440738981446396\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029803616576828063\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 924\n",
            "0.0022925858905252358\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03138300817226991\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 925\n",
            "0.00241407755171307\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.032289562514051795\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 926\n",
            "0.0024838125010809074\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03162354009691626\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 927\n",
            "0.0024325800074550966\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030084360972978175\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 928\n",
            "0.0023141816133060134\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030991816543973982\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 929\n",
            "0.002383985887997999\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03207501256838441\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 930\n",
            "0.002467308659106493\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0316025463398546\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 931\n",
            "0.0024309651030657384\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029657568084076047\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 932\n",
            "0.002281351391082773\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030838777078315616\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 933\n",
            "0.0023722136214088937\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03198779537342489\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 934\n",
            "0.0024605996441096067\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03163871157448739\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 935\n",
            "0.0024337470441913376\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02976517239585519\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 936\n",
            "0.0022896286458350145\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03049006639048457\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 937\n",
            "0.002345389722344967\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031690800562500954\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 938\n",
            "0.00243775388942315\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03137080045416951\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 939\n",
            "0.002413138496474578\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02972376556135714\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 940\n",
            "0.00228644350471978\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030339371762238443\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 941\n",
            "0.0023337978278644956\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03148064750712365\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 942\n",
            "0.0024215882697787424\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031169837224297225\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 943\n",
            "0.002397679786484402\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02977508876938373\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 944\n",
            "0.0022903914437987483\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030257335864007473\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 945\n",
            "0.002327487374154421\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031770190107636154\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 946\n",
            "0.0024438607775104735\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031302399933338165\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 947\n",
            "0.0024078769179490898\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02942596306093037\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 948\n",
            "0.002263535620071567\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029965567286126316\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 949\n",
            "0.002305043637394332\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0314089945750311\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 950\n",
            "0.002416076505771623\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031173613271676004\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 951\n",
            "0.002397970251667385\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029024718329310417\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 952\n",
            "0.002232670640716186\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02990848827175796\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 953\n",
            "0.0023006529439813816\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03137719735968858\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 954\n",
            "0.0024136305661298907\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031059563043527305\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 955\n",
            "0.002389197157194408\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029089342686347663\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 956\n",
            "0.0022376417451036665\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0299031330505386\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 957\n",
            "0.0023002410038875844\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031164847314357758\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 958\n",
            "0.002397295947258289\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030571707640774548\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 959\n",
            "0.002351669818521119\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.028856858960352838\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 960\n",
            "0.002219758381565603\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0301108262501657\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 961\n",
            "0.0023162174038589\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03125216730404645\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 962\n",
            "0.002404012869542035\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.031049704994075\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 963\n",
            "0.0023884388456980768\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029057947569526732\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 964\n",
            "0.0022352267361174408\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029399661463685334\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 965\n",
            "0.002261512420283487\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030939240707084537\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 966\n",
            "0.0023799415928526567\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03053683857433498\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 967\n",
            "0.002348987582641152\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02916068909689784\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 968\n",
            "0.002243129930530603\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029172868351452053\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 969\n",
            "0.0022440667962655425\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030820658896118402\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 970\n",
            "0.002370819915086031\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030665006604976952\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 971\n",
            "0.002358846661921304\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02848069730680436\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 972\n",
            "0.0021908228697541813\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029594135703518987\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 973\n",
            "0.002276471977193768\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.03074449487030506\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 974\n",
            "0.0023649611438696203\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.0304065685486421\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 975\n",
            "0.0023389668114340077\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.028376800008118153\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 976\n",
            "0.0021828307698552427\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02948566945269704\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 977\n",
            "0.0022681284194382336\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030762764276005328\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 978\n",
            "0.0023663664827696406\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030263342894613743\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 979\n",
            "0.0023279494534318265\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.028585706721059978\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 980\n",
            "0.0021989005170046138\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02927248371997848\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 981\n",
            "0.0022517295169214215\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030104639066848904\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 982\n",
            "0.002315741466680685\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030093046138063073\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 983\n",
            "0.002314849702927929\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.028762177913449705\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 984\n",
            "0.0022124752241115156\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02912168053444475\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 985\n",
            "0.0022401292718803654\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030324174324050546\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 986\n",
            "0.002332628794157734\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029861387447454035\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 987\n",
            "0.0022970298036503103\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02822837105486542\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 988\n",
            "0.0021714131580665708\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029348527430556715\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 989\n",
            "0.0022575790331197474\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030075873248279095\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 990\n",
            "0.0023135287114060842\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029883562005124986\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 991\n",
            "0.0022987355388557683\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.028179445303976536\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 992\n",
            "0.002167649638767426\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.028920160024426877\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 993\n",
            "0.002224627694186683\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.030218533938750625\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 994\n",
            "0.002324502610673125\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.02963501971680671\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 995\n",
            "0.0022796169012928237\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.027847154182381928\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 996\n",
            "0.0021420887832601485\n",
            "Computing validation loss\n",
            "2\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029187740990892053\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 997\n",
            "0.002245210845453235\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029973582946695387\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 998\n",
            "0.002305660226668876\n",
            "Computing validation loss\n",
            "1\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "0.029601249028928578\n",
            "The number of items in train is: 13\n",
            "The loss for epoch 999\n",
            "0.002277019156071429\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 1129.8063706505227\n",
            "This model is currently forecasting for: 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['month', 'day', 'day_of_week', 'hour']\n",
            "scaling now\n",
            "CSV Path below\n",
            "df_full.csv\n",
            "Add debugging crap below\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "tensor shapes below\n",
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1, 1])\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       0  1  2  3  4  5  6  7  8  9  ...  PassedTime  Step  TimeConclusion  \\\n",
            "15501  1  0  0  0  0  0  0  0  0  0  ...      0.0000     1         33.0024   \n",
            "15502  1  2  0  0  0  0  0  0  0  0  ...     28.9576     2         32.9998   \n",
            "15503  1  2  3  0  0  0  0  0  0  0  ...     32.9998     3         28.9576   \n",
            "15504  1  2  3  5  0  0  0  0  0  0  ...     33.0024     4          0.0000   \n",
            "15505  1  0  0  0  0  0  0  0  0  0  ...      0.0000     1         33.0061   \n",
            "...   .. .. .. .. .. .. .. .. .. ..  ...         ...   ...             ...   \n",
            "16114  1  0  0  0  0  0  0  0  0  0  ...      0.0000     1         37.9999   \n",
            "16115  1  2  0  0  0  0  0  0  0  0  ...     37.0181     2         37.2333   \n",
            "16116  1  2  3  0  0  0  0  0  0  0  ...     37.2333     3         37.0181   \n",
            "16117  1  2  3  5  0  0  0  0  0  0  ...     37.9999     4          0.0000   \n",
            "16118  1  0  0  0  0  0  0  0  0  0  ...      0.0000     1         40.0041   \n",
            "\n",
            "       original_index  month day  day_of_week  hour      preds  \\\n",
            "15501           15501      7   5            3     0   0.000000   \n",
            "15502           15502      7   5            3     0   0.000000   \n",
            "15503           15503      7   9            0     0   0.000000   \n",
            "15504           15504      8   7            1     0   0.000000   \n",
            "15505           15505      7   5            3     0   0.000000   \n",
            "...               ...    ...  ..          ...   ...        ...   \n",
            "16114           16114      7  26            3     0  30.980867   \n",
            "16115           16115      7  27            4     0  30.980947   \n",
            "16116           16116      7  27            4     0  30.980551   \n",
            "16117           16117      9   2            6     0  30.980778   \n",
            "16118           16118      7  27            4     0  30.980770   \n",
            "\n",
            "       pred_TimeConclusion  \n",
            "15501             0.000000  \n",
            "15502             0.000000  \n",
            "15503             0.000000  \n",
            "15504             0.000000  \n",
            "15505             0.000000  \n",
            "...                    ...  \n",
            "16114            30.980867  \n",
            "16115            30.980947  \n",
            "16116            30.980551  \n",
            "16117            30.980778  \n",
            "16118            30.980770  \n",
            "\n",
            "[618 rows x 27 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1405.)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1053: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Now plotting final plots\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.120 MB of 0.120 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7e61de24ede4a4fb5d74764b37b53d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>999</td></tr><tr><td>loss</td><td>0.00228</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">balmy-sweep-1</strong>: <a href=\"https://wandb.ai/ronildosilva/if-hd17-flow-forecast/runs/6hd5aajp\" target=\"_blank\">https://wandb.ai/ronildosilva/if-hd17-flow-forecast/runs/6hd5aajp</a><br/>Synced 5 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221003_183008-6hd5aajp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "from flood_forecast.trainer import train_function\n",
        "\n",
        "\n",
        "#sweep_id = wandb.sweep(wandb_sweep_config_full, project=PROJECT_NAME)\n",
        "sweep_id = wandb.sweep(wandb_sweep_config_full, project=PROJECT_NAME)\n",
        "\n",
        "file_path = \"df_full.csv\"\n",
        "\n",
        "#wandb.agent(sweep_id, lambda: train_function(\"PyTorch\", make_config_file(file_path, \"01010500\", \"FVE\", None)))\n",
        "\n",
        "#model = train_function(\"PyTorch\", make_config_file(file_path, \"01010500\", \"FVE\", None))\n",
        "#model = train_function(\"PyTorch\", make_config_file(file_path))\n",
        "wandb.agent(sweep_id, lambda: train_function(\"PyTorch\", make_config_file(file_path)))"
      ],
      "id": "648be723"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efhkpGKdG9RP"
      },
      "outputs": [],
      "source": [
        "#model.test_data.df"
      ],
      "id": "efhkpGKdG9RP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMMsTqlr45Jt"
      },
      "outputs": [],
      "source": [],
      "id": "JMMsTqlr45Jt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mewos--qVe5i"
      },
      "source": [
        "**crisp-sweep-1**\n",
        "- https://wandb.ai/ronildosilva/if-hd17-flow-forecast/runs/ch8h6nio?workspace=user-ronildosilva\n",
        "- 2.689311174001041\n",
        "- `['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', 'Duration', 'PassedTime', 'Step', 'TimeConclusion']`"
      ],
      "id": "mewos--qVe5i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**helpful-sweep-1**\n",
        "- https://wandb.ai/ronildosilva/if-hd17-flow-forecast/runs/ost3te7b\n",
        "- 13.95808643138184\n",
        "- `['TimeConclusion', 'Duration', 'PassedTime', 'Step', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14']`\n"
      ],
      "metadata": {
        "id": "F3TTLPbpS7Qu"
      },
      "id": "F3TTLPbpS7Qu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "****\n",
        "- https://wandb.ai/ronildosilva/if-hd17-flow-forecast/sweeps/dkul679r?workspace=user-ronildosilva\n",
        "- 13.958099075925114\n",
        "\n",
        "- `['TimeConclusion', 'Duration', 'PassedTime', 'Step']`"
      ],
      "metadata": {
        "id": "jPXdTaoXoYHs"
      },
      "id": "jPXdTaoXoYHs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**balmy-sweep-1**\n",
        "- https://wandb.ai/ronildosilva/if-hd17-flow-forecast/runs/6hd5aajp?workspace=user-ronildosilva\n",
        "- 13.958120385872103\n",
        "- `['TimeConclusion', 'PassedTime']`"
      ],
      "metadata": {
        "id": "ahCyl4ImwflF"
      },
      "id": "ahCyl4ImwflF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rntzyT_fVsxq"
      },
      "outputs": [],
      "source": [],
      "id": "rntzyT_fVsxq"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2WQQoNKw_93"
      },
      "id": "f2WQQoNKw_93",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 29.538863,
      "end_time": "2021-10-18T07:45:15.523057",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-10-18T07:44:45.984194",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7e61de24ede4a4fb5d74764b37b53d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72df380e9fd14a4ab03fcd30b5b21e2d",
              "IPY_MODEL_3ec2a28e8a564115b5ad061c62486b94"
            ],
            "layout": "IPY_MODEL_91cb40f844d842b2bcdf12c133196b4a"
          }
        },
        "72df380e9fd14a4ab03fcd30b5b21e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c67385c2c1745fbb2b249f2761a0420",
            "placeholder": "​",
            "style": "IPY_MODEL_99cb58c5416745238be88376b0d471d9",
            "value": "0.565 MB of 0.565 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "3ec2a28e8a564115b5ad061c62486b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d03d00716ba14442933f05d9ce654da1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2760f9dad4ec400eb06f1de53b705428",
            "value": 1
          }
        },
        "91cb40f844d842b2bcdf12c133196b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c67385c2c1745fbb2b249f2761a0420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99cb58c5416745238be88376b0d471d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d03d00716ba14442933f05d9ce654da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2760f9dad4ec400eb06f1de53b705428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}